---
title: "Leave-one-out cross-validation for non-factorizable normal models"
shorttitle: "Cross-validation for non-factorizable models"
author: 
  - name: Paul-Christian Bürkner
    affiliation: "1"
    corresponding: no
    email: paul.buerkner@gmail.com
    address: Department of Psychology, University of Münster, Germany
  - name: Jonah Gabry
    affiliation: "2"
  - name: Aki Vehtari
    affiliation: "3"
    corresponding: yes
    email: Aki.Vehtari@aalto.fi
    address: Department of Computer Science, Aalto University, Finland
affiliation:
  - id: 1
    institution: Department of Psychology, University of Münster, Germany
  - id: 2
    institution: Institute for Social and Economic Research in Policy, Columbia University, USA
  - id: 3
    institution: Department of Computer Science, Aalto University, Finland
abstract: |
  Cross-validation can be used to measure a model's predictive accuracy for
  instance for the purpose of model comparison or selection. As exact
  cross-validation is often practically infeasible for Bayesian models because
  it requires too much time, approximate cross-validation methods have been
  developed; most notably methods for leave-one-out cross-validation (LOO-CV).
  However, standard LOO-CV requires the likelihood to be factorizable, that is
  the observations have to be conditionally independent given the model
  parameters. Unfortunately, some important statistical models most notably in the
  context of temporal and spatial statistics are non-factorizable, but LOO-CV may still
  be an important measure for these models. For this reason, we derive how to
  compute and validate exact and approximate LOO-CV for non-factorizable models
  that follow a multivariate normal likelihood.
keywords: cross-validation, Pareto-smoothed importance-sampling,
  non-factorizable models, SAR models
lang: english
output:
  papaja::apa6_pdf:
    highlight: default
class: doc  # man
lineno: true
figsintext: true
floatsintext: true
numbersections: true
bibliography: 
  - psis_non_factorizable_models.bib
header-includes:
   - \usepackage{mathtools}
   - \usepackage[utf8]{inputenc}
   - \usepackage[T1]{fontenc}
   - \usepackage{textcomp}
   - \usepackage{graphicx,pdflscape}
   - \usepackage{geometry}
   - \usepackage{amsmath}
   - \usepackage{float}
   - \usepackage{supertabular}
   - \usepackage{booktabs,caption,fixltx2e}
   - \usepackage[flushleft]{threeparttable}
   - \usepackage{natbib}
   - \usepackage{tcolorbox}
   - \usepackage{paralist}
   - \usepackage{multicol}
   - \usepackage[onehalfspacing]{setspace}
   - \newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
editor_options: 
  chunk_output_type: console
---

```{r setup, message = FALSE, warning = FALSE, results = "hide", cache = FALSE}
library(knitr)
library(kableExtra)
library(tidyverse)
library(papaja)
library(brms)
library(patchwork)
library(loo)
library(bayesplot)

# set ggplot theme
color_scheme_set("brightblue")
theme_set(theme_default())

# set rstan options
rstan::rstan_options(auto_write = TRUE)
options(mc.cores = max(1, parallel::detectCores() - 1))

# enables / disables caching for all chunks of code
knitr::opts_chunk$set(
  cache = TRUE,
  warning = FALSE, 
  message = FALSE  
)
options(knitr.kable.NA = '')

# how to use papaja ? https://crsh.github.io/papaja_man/introduction.html
```

# Introduction

After fitting a statistical model, we often want to measure its predictive
accuracy, for instance for the purpose of model comparison or selection
[@geisser1979; @vehtari2002; @ando2010; @vehtari2012]. In the absence of actual
new data to predict, one general approach to evaluating a model's predictive
accuracy is cross-validation [@vehtari2002]. When doing cross-validation, the
data is split into two subsets. Based on the first subset we fit the statistical
model and then evaluate its predictive accuracy for the second subset. We may do
this once or many times each time leaving out another subset.

One widely applied type of cross-validation is *leave-one-out cross-validation*
(LOO-CV), where each time a single observation is left out and then predicted
based on the model fit to the remaining data [@vehtari2017loo]. Predictive
accuracy is evaluated by first computing the expected log predictive density of
the left-out observation and then taking the sum of these values over all observations
to obtain the expected log predictive density as a single measure of predictive
accuracy. Unfortunately, exact LOO-CV is costly as it requires to fit the model
as many times are there are observations in the data. Depending on the size of
the data, complexity of the model, and estimation method, this can be
practically infeasible as it simply requires too much time [@vehtari2017loo].
For this reason, approximate versions of LOO-CV have been developed, most
notably approximations via Pareto-smoothed importance-sampling 
[PSIS-LOO-CV; @vehtari2017loo; @vehtari2017psis], which is applicable to
Bayesian models.

A standard assumption of any such LOO-CV approach is that the joint likelihood
of the model over all observations has to be factorizable, that is the
observations have to be pairwise conditionally independent given the model
parameters. The purpose of the present paper is to generalize PSIS-LOO-CV to
non-factorized or non-factorizable models where observations are dependent even
after conditioning on the model parameters.

## Approximate LOO-CV using integrated importance-sampling

We start by introducing the mathematical basis of approximative LOO-CV. We index
observations by $i$ and denote the corresponding response value by $y_i$.
Further, we use $y$ to indicate the response vector of all observations and
$y_{-i}$ to indicate the response vector without the $i$th value. Model
parameters are referred to as $\theta$. Throughout, a Bayesian model
specification and estimation via Markov chain Monte Carlo (MCMC) methods is
assumed. To obtain the leave-one-out predictive density $p(y_i \,|\, y_{-i})$
we need to integrate over $\theta$:

\begin{equation}
p(y_i\,|\,y_{-i}) =
  \int p(y_i\,|\, y_{-i}, \theta) \, p(\theta\,|\, y_{-i}) \,d \theta.
\end{equation}

Here, $p(\theta\,|\, y_{-i})$ is the leave-one-out posterior distribution for
$\theta$, that is, the posterior distribution for $\theta$ obtained by fitting
the model while holding out the $i$th observation. 

To avoid the cost of sampling from $N$ leave-one-out posteriors, it is possible
to take the posterior draws $\theta^{(s)}$ $(s=1,\ldots,S)$, from the
\emph{full} posterior $p(\theta\,|\, y)$, and then approximate the above integral
using integrated importance sampling [see Section 3.6.1 in @vehtari2016]:

\begin{equation}
 p(y_i\,|\, y_{-i}) \approx
   \frac{ \sum_{s=1}^S p(y_i\,|\,y_{-i},\,\theta^{(s)}) \,w_i^{(s)}}{ \sum_{s=1}^S w_i^{(s)}}.
\end{equation}

In the above equation, $w_i^{(s)}$ are importance weights to be computed as 
follows. First we compute the raw importance ratios

\begin{equation}
  r_i^{(s)} \propto \frac{1}{p(y_i \,|\, y_{-i}, \, \theta^{(s)})},
\end{equation}

and then stabilize them using Pareto-smoothed importance-sampling to
obtain the weights $w_i^{(s)}$ [@vehtari2017loo; @vehtari2017psis]. The
resulting approximation is referred to as PSIS-LOO-CV [@vehtari2017loo].

# Leave-one-out cross validation for non-factorizable models {#nf-loo-cv}

When computing approximate LOO-CV after fitting
a Bayesian model, the first step is to calculate the *pointwise* log-likelihood
for every response value $y_i, \: i = 1, \ldots, N$. This is straightforward for
*factorizable* models in which response values are conditionally independent
given the model parameters $\theta$ and the likelihood can be written in the
familiar form

\begin{equation}
p(y \,|\, \theta) = \prod_{i=1}^N p(y_i \,|\, \theta).
\end{equation}

The function $p$ will be either a probability density function (PDF) or a
probability mass function (PMF) depending on whether we have a continuous or
discrete outcome. When $p(y)$ can be factorized in this way, the conditional
pointwise log-likelihood can be obtained easily by computing 
$\log p(y_i \,|\, \theta)$ for each $i$. We then save each of these individual
contributions to the log-likelihood rather than simply summing them to obtain
the total log-likelihood.

The situation is more complicated for *non-factorizable* models in which
response values are not conditionally independent. When there is residual
dependency even after accounting for the model parameters $\theta$, the
conditional pointwise log-likelihood has the general form $\log p(y_i \,|\,
y_{-i}, \theta)$, where, again, $y_{-i}$ denotes all response values except
observation $i$.

## LOO-CV for multivariate normal models

Although computing the pointwise log-likelihood for non-factorizable models is
often impossible, there is a large class of multivariate normal models for which
an analytical solution is available. These equations were initially derived by
@sundararajan2001 with a focus on the special case of a zero-mean Gaussian
process model with prior covariance $K$ and residual standard deviation
$\sigma$,

\begin{equation}
y \sim {\mathrm N}(0, \, K+\sigma^2 I),
\end{equation}

where $I$ is the identity matrix of appropriate dimension and $C = K+\sigma^2 I$
is the covariance matrix of the model. Sundararajan and Keerthi's equations are
not usually used for LOO-CV of Gaussian process models, as in most the cases,
Gaussian processes are combined with a factorizable likelihood so that simpler
equations for univariate distributions can be applied. What makes Sundararajan
and Keerthi's equations helpful for the purpose of the present paper, is our
observation that their derivations make no use of the special form of $C$ for
Gaussian process models and thus immediately generalize to the case of an
arbitrary invertible covariance matrix $C$. For such models, the LOO predictive
mean and standard deviation can be computed as follows:

\begin{align}
\label{ypredpars}
  \mu_{\tilde{y},-i} &= y_i-\bar{c}_{ii}^{-1} g_i \nonumber \\
  \sigma_{\tilde{y},-i} &= \sqrt{\bar{c}_{ii}^{-1}},
\end{align}

where $g_i = \left[C^{-1} y\right]_i$ and $\bar{c}_{ii} = \left[C^{-1}\right]_{ii}$. The log predictive density of the $i$th observation is then computed as

\begin{equation}
  \log p(y_i \,|\, y_{-i},\theta)
  = - \frac{1}{2}\log(2\pi)
  - \frac{1}{2}\log \sigma^2_{-i}
  - \frac{1}{2}\frac{(y_i-\mu_{-i})^2}{\sigma^2_{-i}}.
\end{equation}

Expressing this same equation in terms of $g_i$ and $\bar{c}_{ii}$, the log
predictive density becomes:

\begin{equation}
  \log p(y_i \,|\, y_{-i},\theta)
  = - \frac{1}{2}\log(2\pi)
  + \frac{1}{2}\log \bar{c}_{ii}
  - \frac{1}{2}\frac{g_i^2}{\bar{c}_{ii}}
\end{equation}

(note that @vehtari2016 has a typo in the corresponding Equation 34). From these equations we can now derive a recipe for obtaining the conditional pointwise log-likelihood for _all_ models that can be expressed conditionally in terms of a multivariate normal with invertible covariance matrix $C$.

## Exact LOO-CV with re-fitting

In order to validate the approximate LOO-CV procedure, and also in order to allow
exact computations to be made for a small number of leave-one-out folds for
which the Pareto-$k$ diagnostic [@vehtari2017psis] indicates an unstable
approximation, we need to consider how we might to do _exact_ LOO-CV
for a non-factorizable model. In the case of a Gaussian process that has the
marginalization property, we could just drop the one row and column of $C$
corresponding to the held out out observation. This does not hold in general for
multivariate normal models, however, and to keep the original prior we may need
to maintain the full covariance matrix $C$ even when one of the observations is
left out.

The solution is to model $y_i$ as a missing observation and estimate it along
with all of the other model parameters. For a conditional multivariate normal
model, $\log p(y_i\,|\,y_{-i})$ can be computed as follows. First, we model
$y_i$ as missing and denote the corresponding parameter $y_i^{\mathrm{mis}}$.
Then, we define

\begin{equation}
y_{\mathrm{mis}(i)} = (y_1, \ldots, y_{i-1}, y_i^{\mathrm{mis}}, y_{i+1}, \ldots, y_N).
\end{equation}

to be the same as the full set of observations $y$, except replacing $y_i$ with
the parameter $y_i^{\mathrm{mis}}$.

Second, we compute the LOO predictive mean and standard deviations as above, but
replace $y$ with $y_{\mathrm{mis}(i)}$ in the computation of
$\mu_{\tilde{y},-i}$:

\begin{equation}
\mu_{\tilde{y},-i} = y_{{\mathrm{mis}}(i)}-\bar{c}_{ii}^{-1}g_i,
\end{equation}

where in this case we have

\begin{equation}
g_i = \left[ C^{-1} y_{\mathrm{mis}(i)} \right]_i.
\end{equation}

The conditional log predictive density is then computed with the above
$\mu_{\tilde{y},-i}$ and the left out observation $y_i$:

\begin{equation}
  \log p(y_i\,|\,y_{-i},\theta)
  = - \frac{1}{2}\log(2\pi)
  - \frac{1}{2}\log \sigma^2_{\tilde{y},-i}
  - \frac{1}{2}\frac{(y_i-\mu_{\tilde{y},-i})^2}{\sigma^2_{\tilde{y},-i}}.
\end{equation}

Finally, the leave-one-out predictive distribution can then be estimated as

\begin{equation}
 p(y_i\,|\,y_{-i}) \approx \frac{1}{S} \sum_{s=1}^S p(y_i\,|\,y_{-i}, \theta_{-i}^{(s)}),
\end{equation}

where $\theta_{-i}^{(s)}$ are draws from the posterior distribution
$p(\theta\,|\,y_{\mathrm{mis}(i)})$.

# Case Study

A common non-factorizable multivariate normal model is the simultaneously
autoregressive (SAR) model, which is frequently used for spatially correlated
data. The lagged SAR model is defined as

\begin{equation}
y = \rho Wy + \eta + \epsilon
\end{equation}

or equivalently

\begin{equation}
(I - \rho W)y = \eta + \epsilon,
\end{equation}

where $\rho$ is the spatial correlation parameter and $W$ is a user-defined
weight matrix. The matrix $W$ has entries $w_{ii} = 0$ along the diagonal and
the off-diagonal entries $w_{ij}$ are larger when areas $i$ and $j$ are closer
to each other. In a linear model, the predictor term $\eta$ is given by 
$\eta = X \beta$ with design matrix $X$ and regression coefficients $\beta$. 
However, since the above equation holds for arbitrary $\eta$, these results are 
not restricted to linear models. If we have $\epsilon \sim {\mathrm N}(0, \,\sigma^2 I)$, it follows that

\begin{equation}
(I - \rho W)y \sim {\mathrm N}(\eta, \sigma^2 I).
\end{equation}

<!--
This corresponds to the following log PDF coded in **Stan**:

```{lpdf, eval=FALSE}
/** 
 * Normal log-pdf for spatially lagged responses
 * 
 * @param y Vector of response values.
 * @param mu Mean parameter vector.
 * @param sigma Positive scalar residual standard deviation.
 * @param rho Positive scalar autoregressive parameter.
 * @param W Spatial weight matrix.
 *
 * @return A scalar to be added to the log posterior.
 */
real normal_lagsar_lpdf(vector y, vector mu, real sigma, 
                        real rho, matrix W) {
  int N = rows(y);
  real inv_sigma2 = 1 / square(sigma);
  matrix[N, N] W_tilde = -rho * W;
  vector[N] half_pred;
  
  for (n in 1:N) W_tilde[n,n] += 1;
  
  half_pred = W_tilde * (y - mdivide_left(W_tilde, mu));
  
  return 0.5 * log_determinant(crossprod(W_tilde) * inv_sigma2) -
         0.5 * dot_self(half_pred) * inv_sigma2;
}
```
-->

For the purpose of computing LOO-CV, it makes sense to rewrite the SAR model in
slightly different form. Conditional on $\rho$, $\eta$, and $\sigma$, 
if we write

\begin{equation}
y-(I-\rho W)^{-1}\eta \sim {\mathrm N}(0, \sigma^2(I-\rho W)^{-1}(I-\rho W)^{-T}),
\end{equation}

or more compactly, with $\widetilde{W}=(I-\rho W)$,

\begin{equation}
y-\widetilde{W}^{-1}\eta \sim {\mathrm N}(0, \sigma^2(\widetilde{W}^{T}\widetilde{W})^{-1}),
\end{equation}

then this has the same form as the zero mean Gaussian process from above. Accordingly, we can compute the leave-one-out predictive densities with the equations from @sundararajan2001, replacing $y$ with $(y-\widetilde{W}^{-1}\eta)$ and taking the covariance matrix $C$ to be $\sigma^2(\widetilde{W}^{T}\widetilde{W})^{-1}$.

## Neighborhood Crime in Columbus, Ohio

```{r, cache=FALSE}
SEED <- 10001 
set.seed(SEED) # only sets seed for R (seed for Stan set later)
# loads COL.OLD data frame and COL.nb neighbor list
data(oldcol, package = "spdep") 
```

In order to demonstrate how to carry out the computations implied by these
equations, we will first fit a lagged SAR model to data on crime in 49 different
neighborhoods of Columbus, Ohio during the year 1980. The data was originally
described in @anselin1988 and ships with the spdep package [@bivand2015].

In addition to the loo package [@loo2018], for this analysis we use the brms interface [@brms1;@brms2] to Stan [@carpenter2017] to generate a Stan program and fit the model, and also the bayesplot [@bayesplot] and ggplot2 [@ggplot2] packages for plotting. The three variables in the data set relevant to this example are: `CRIME`: the number of residential burglaries and vehicle thefts per thousand households in the neighborhood, `HOVAL`: housing value in units of \$1000 USD, and `INC`: household income in units of \$1000 USD. We will also use the object `COL.nb`, which is a list containing information about which neighborhoods border each other. From this list we will be able to construct the weight matrix to used to help account for the spatial dependency among the observations. The complete R code for this case study can be found at (http://mc-stan.org/loo/articles/loo2-non-factorizable.html).

A model predicting `CRIME` from `INC` and `HOVAL`, while accounting for the
spatial dependency via an SAR structure, can be specified in brms as
follows:

```{r fit_nb_dummy, echo=TRUE, eval=FALSE}
brm(CRIME ~ INC + HOVAL, data = COL.OLD, autocor = cor_lagsar(COL.nb))
```

```{r fit_nb, results="hide"}
fit_nb <- brm(
  CRIME ~ INC + HOVAL, 
  data = COL.OLD,
  autocor = cor_lagsar(COL.nb),
  seed = SEED
)
```

In Figure \@ref(fig:plot-lagsar), we see that both higher income and higher housing value predict lower crime rates in the neighborhood. Moreover, there seems to be substantial spatial correlation between adjacent neighborhoods, as indicated by the posterior distribution of the `lagsar` parameter.

```{r plot-lagsar, fig.cap="Posterior distribution of selected parameters of the lagged SAR model along with posterior median and 50% central interval.", fig.width=10, fig.asp=0.3}
par <- as.matrix(fit_nb, pars = "b_INC")
colnames(par) <- "Coefficient of INC"
estimates <- quantile(par, probs = c(0.25, 0.5, 0.75))
gginc <- mcmc_hist(par) + 
  vline_at(estimates, linetype = 2, size = 1)

par <- as.matrix(fit_nb, pars = "b_HOVAL")
colnames(par) <- "Coefficient of HOVAL"
estimates <- quantile(par, probs = c(0.25, 0.5, 0.75))
gghoval <- mcmc_hist(par) + 
  vline_at(estimates, linetype = 2, size = 1)

par <- as.matrix(fit_nb, pars = "lagsar")
colnames(par) <- "lagsar autocorrelation"
estimates <- quantile(par, probs = c(0.25, 0.5, 0.75))
gglagsar <- mcmc_hist(par) + 
  vline_at(estimates, linetype = 2, size = 1) 
# + ggtitle("lagsar: posterior median and 50% central interval")

gginc + gghoval + gglagsar
```

## Approximate and exact LOO-CV

After fitting the model, the next step is to compute the pointwise log-likelihood values needed for approximate LOO-CV. To do this we use the recipe laid out in Section \ref{nf-loo-cv}.

```{r}
posterior <- as.data.frame(fit_nb)
y <- fit_nb$data$CRIME
N <- length(y)
S <- nrow(posterior)
loglik <- yloo <- sdloo <- matrix(nrow = S, ncol = N)

for (s in 1:S) {
  p <- posterior[s, ]
  eta <- p$b_Intercept + p$b_INC * fit_nb$data$INC + p$b_HOVAL * fit_nb$data$HOVAL
  W_tilde <- diag(N) - p$lagsar * fit_nb$autocor$W
  Cinv <- t(W_tilde) %*% W_tilde / p$sigma^2
  g <- Cinv %*% (y - solve(W_tilde, eta))
  cbar <- diag(Cinv)
  yloo[s, ] <- y - g / cbar
  sdloo[s, ] <- sqrt(1 / cbar)
  loglik[s, ] <- dnorm(y, yloo[s, ], sdloo[s, ], log = TRUE)
}

# use loo for psis smoothing
log_ratios <- -loglik
psis_result <- psis(log_ratios)
```

The quality of the PSIS-LOO approximation can be investigated graphically by plotting the Pareto-$k$ estimate for each observation. Ideally, they should not exceed $0.5$, but in practice the algorithm turns out to be robust up to values of $0.7$ [@vehtari2017loo;@vehtari2017psis]. In Figure \@ref(fig:psis-res-nb), we see that the fourth observation is problematic and so may reduce the accuracy of the LOO-CV approximation.

```{r psis-res-nb, cache = FALSE, fig.cap="PSIS diagnostic plot showing the Pareto-$k$-estimate of each observation.", fig.width=10, fig.asp=0.5}
plot(psis_result, label_points = TRUE, main = "")
```

<!--
We can also check that the conditional leave-one-out predictive distribution
equations work correctly as illustrated in Figure \@ref(fig:yloo) using a single posterior draw.

```{r yloo, cache = FALSE, fig.cap="Comparison of observed responses (y) and predicted responses based on approximate leave-one-out cross-validation (yloo) using a single posterior draw."}
yloo_sub <- yloo[S, ]
sdloo_sub <- sdloo[S, ]
df <- data.frame(
  y = y, 
  yloo = yloo_sub,
  ymin = yloo_sub - sdloo_sub * 2,
  ymax = yloo_sub + sdloo_sub * 2
)
ggplot(data = df, aes(x = y, y = yloo, ymin = ymin, ymax = ymax)) +
  geom_errorbar(
    width = 1, 
    color = "skyblue3", 
    position = position_jitter(width = 0.25)
  ) +
  geom_abline(color = "gray30", size = 1.2) +
  geom_point()
```
-->

```{r, warning=FALSE}
psis_loo <- loo(loglik)
```

The PSIS-LOO-CV to approximation of the expected log predictive density for new
data reveals $\text{elpd}_{\text{approx}} =$ `r psis_loo$estimates[1, 1]`. This
result still needs to be validated against exact LOO-CV, which is somewhat more
involved, as we need to re-fit the model $N$ times each time leaving out a
single observations. For the lagged SAR model, we cannot just ignore the
held-out observation entirely as this will change the prior of the other
observations. In other words, the lagged SAR model does not have the
marginalization property that holds, for instance, for Gaussian process models.
Instead, we have to model the held-out observation as a missing value, which is
to be estimated along with the other model parameters (see the case study 
section in http://mc-stan.org/loo/articles/loo2-non-factorizable.html for 
details on the R code).

```{r fit_dummy, cache = TRUE}
# see help("mi", "brms") for details on the mi() usage
fit_dummy <- brm(
  CRIME | mi() ~ INC + HOVAL, 
  data = COL.OLD,
  autocor = cor_lagsar(COL.nb), 
  chains = 0
)
```

<!--
Next, we fit the model $N$ times, each time leaving out a single observation and
then computing the log predictive density for that observation. For obvious
reasons, this takes much longer than the approximation we computed above, but it
is necessary in order to validate the approximate LOO-CV method. Thanks 
to the PSIS-LOO approximation, in general doing these slow exact computations
can be avoided.
-->

```{r exact-loo-cv, results="hide", message=FALSE, warning=FALSE, cache = TRUE}
S <- 500
res <- vector("list", N)
loglik <- matrix(nrow = S, ncol = N)
for (i in seq_len(N)) {
  dat_mi <- COL.OLD
  dat_mi$CRIME[i] <- NA
  fit_i <- update(fit_dummy, newdata = dat_mi, 
                  # just for vignette
                  chains = 1, iter = S * 2)
  posterior <- as.data.frame(fit_i)
  yloo <- sdloo <- rep(NA, S)
  for (s in seq_len(S)) {
    p <- posterior[s, ]
    y_miss_i <- y
    y_miss_i[i] <- p$Ymi
    eta <- p$b_Intercept + p$b_INC * fit_i$data$INC + p$b_HOVAL * fit_i$data$HOVAL
    W_tilde <- diag(N) - p$lagsar * fit_i$autocor$W
    Cinv <- t(W_tilde) %*% W_tilde / p$sigma^2
    g <- Cinv %*% (y_miss_i - solve(W_tilde, eta))
    cbar <- diag(Cinv);
    yloo[s] <- y_miss_i[i] - g[i] / cbar[i]
    sdloo[s] <- sqrt(1 / cbar[i])
    loglik[s, i] <- dnorm(y[i], yloo[s], sdloo[s], log = TRUE)
  }
  ypred <- rnorm(S, yloo, sdloo)
  res[[i]] <- data.frame(y = c(posterior$Ymi, ypred))
  res[[i]]$type <- rep(c("pp", "loo"), each = S)
  res[[i]]$obs <- i
}
res <- do.call(rbind, res)
```

A first step in the validation of the pointwise predictive density is to compare
the distribution of the implied response values for the left-out observation
using the pointwise mean and standard deviation from (\ref{ypredpars}) to the
distribution of the $y_i^{\mathrm{mis}}$ posterior-predictive values estimated
as part of the model. If the pointwise predictive density is correct, the two
distributions should match very closely (up to sampling error). In Figure
\@ref(fig:yplots), we overlay these two distributions for the first four
observations and see that they match very closely (as is the case for all $49$
observations of in this example).

```{r yplots, cache = FALSE, fig.width=10, out.width="95%", fig.asp = 0.3, fig.cap="Implied response values of the first four observations computed (a) after model fitting (type = 'loo') and (b) as part of the model in the form of posterior-predictive draws for the missing observation (type = 'pp')."}
res_sub <- res[res$obs %in% 1:4, ]
ggplot(res_sub, aes(y, fill = type)) +
  geom_density(alpha = 0.6) +
  facet_wrap("obs", scales = "fixed", ncol = 4)
```

```{r loo_exact, cache=FALSE}
log_mean_exp <- function(x) {
  # more stable than log(mean(exp(x)))
  max_x <- max(x)
  max_x + log(sum(exp(x - max_x))) - log(length(x))
}
exact_elpds <- apply(loglik, 2, log_mean_exp)
exact_elpd <- sum(exact_elpds)
```

In the final step, we compute the pointwise predictive density based on the
exact LOO-CV and compare it to the approximate PSIS-LOO-CV result computed
earlier. The results of the approximate ($\text{elpd}_{\text{approx}} =$ 
`r psis_loo$estimates[1, 1]`) and exact LOO-CV ($\text{elpd}_{\text{exact}} =$ 
`r exact_elpd`) are similar but not as close as we would expect if there were no
problematic observations. We can investigate this issue more closely by plotting
the approximate against the exact pointwise ELPD values.

```{r elpd-compare, fig.cap = "Comparison of approximate and exact pointwise elpd values for the SAR model. Problematic observations are marked as red dots.", fig.height=2.5, fig.width=5}
df <- data.frame(
  approx_elpd = psis_loo$pointwise[, "elpd_loo"],
  exact_elpd = exact_elpds
)
ggplot(df, aes(x = approx_elpd, y = exact_elpd)) +
  geom_abline(color = "gray30") +
  geom_point(size = 2) +
  geom_point(data = df[4, ], size = 3, color = "red3") +
  xlab("Approximate elpds") +
  ylab("Exact elpds") #+
  #coord_fixed(xlim = c(-16, -3), ylim = c(-16, -3)) 
```

In Figure \@ref(fig:elpd-compare), the fourth data point -- the observation
flagged as problematic by the PSIS-LOO approximation -- is colored in red and is
the clear outlier. Otherwise, the correspondence between the exact and
approximate values is strong. In fact, summing over the pointwise ELPD values
and leaving out the fourth observation yields practically equivalent results for
approximate and exact LOO-CV ($\text{elpd}_{\text{approx},-4} =$ 
`r sum(psis_loo$pointwise[-4, "elpd_loo"])` vs. $\text{elpd}_{\text{exact},-4} =$
`r sum(exact_elpds[-4])`). From this we can conclude that the difference we
found when including *all* observations does not indicate an error in the
implementation of the approximate LOO-CV but rather a violation of its
assumptions.

# Conclusion

In summary, we have shown how to set up and validate approximate and exact
LOO-CV for non-factorizable multivariate normal models. We demonstrated the
usefulness of our approach with a case study involving the non-factorizable
spatial SAR model. Although we motivated the present paper by means of
non-factorizable models (i.e. models that cannot be factorized at all), we note
that our approach also works for any Bayesian model that can be expressed in
terms of a multivariate normal likelihood. That is, we can also apply it to
models that are factorizable but for which the factorized representation is
difficult to compute or not available to the researcher for some other reasons.

# Acknowledgements

We thank Daniel Simpson for useful discussion and the Academy of Finland
(grants 298742, 313122) for partial support of this work.

<br />

# References {-}

<div id="refs"></div>
